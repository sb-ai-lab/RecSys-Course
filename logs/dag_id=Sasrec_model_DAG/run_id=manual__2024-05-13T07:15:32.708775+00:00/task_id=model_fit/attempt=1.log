[2024-05-13T07:15:50.142+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Sasrec_model_DAG.model_fit manual__2024-05-13T07:15:32.708775+00:00 [queued]>
[2024-05-13T07:15:50.149+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Sasrec_model_DAG.model_fit manual__2024-05-13T07:15:32.708775+00:00 [queued]>
[2024-05-13T07:15:50.149+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2024-05-13T07:15:50.158+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): model_fit> on 2024-05-13 07:15:32.708775+00:00
[2024-05-13T07:15:50.167+0000] {standard_task_runner.py:57} INFO - Started process 409 to run task
[2024-05-13T07:15:50.170+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'Sasrec_model_DAG', 'model_fit', 'manual__2024-05-13T07:15:32.708775+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/sasrec_dag.py', '--cfg-path', '/tmp/tmp6kpkzg3j']
[2024-05-13T07:15:50.173+0000] {standard_task_runner.py:85} INFO - Job 5: Subtask model_fit
[2024-05-13T07:15:50.206+0000] {task_command.py:415} INFO - Running <TaskInstance: Sasrec_model_DAG.model_fit manual__2024-05-13T07:15:32.708775+00:00 [running]> on host a7d11f6dcbcd
[2024-05-13T07:15:50.264+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Sasrec_model_DAG' AIRFLOW_CTX_TASK_ID='model_fit' AIRFLOW_CTX_EXECUTION_DATE='2024-05-13T07:15:32.708775+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-05-13T07:15:32.708775+00:00'
[2024-05-13T07:15:50.286+0000] {instantiator.py:21} INFO - Created a temporary directory at /tmp/tmpyqbz_91b
[2024-05-13T07:15:50.287+0000] {instantiator.py:76} INFO - Writing /tmp/tmpyqbz_91b/_remote_module_non_scriptable.py
[2024-05-13T07:15:50.550+0000] {log.py:232} WARNING - INFO: GPU available: False, used: False
[2024-05-13T07:15:50.550+0000] {rank_zero.py:63} INFO - GPU available: False, used: False
[2024-05-13T07:15:50.551+0000] {log.py:232} WARNING - INFO: TPU available: False, using: 0 TPU cores
[2024-05-13T07:15:50.551+0000] {rank_zero.py:63} INFO - TPU available: False, using: 0 TPU cores
[2024-05-13T07:15:50.551+0000] {log.py:232} WARNING - INFO: IPU available: False, using: 0 IPUs
[2024-05-13T07:15:50.551+0000] {rank_zero.py:63} INFO - IPU available: False, using: 0 IPUs
[2024-05-13T07:15:50.551+0000] {log.py:232} WARNING - INFO: HPU available: False, using: 0 HPUs
[2024-05-13T07:15:50.551+0000] {rank_zero.py:63} INFO - HPU available: False, using: 0 HPUs
[2024-05-13T07:15:50.576+0000] {log.py:232} WARNING - WARNING: Missing logger folder: model_logs/train/SASRec_example
[2024-05-13T07:15:50.576+0000] {csv_logs.py:174} WARNING - Missing logger folder: model_logs/train/SASRec_example
[2024-05-13T07:15:50.579+0000] {log.py:232} WARNING - INFO: 
  | Name   | Type             | Params
--------------------------------------------
0 | _model | SasRecModel      | 158 K 
1 | _loss  | CrossEntropyLoss | 0     
--------------------------------------------
158 K     Trainable params
0         Non-trainable params
158 K     Total params
0.636     Total estimated model params size (MB)
[2024-05-13T07:15:50.579+0000] {model_summary.py:94} INFO - 
  | Name   | Type             | Params
--------------------------------------------
0 | _model | SasRecModel      | 158 K 
1 | _loss  | CrossEntropyLoss | 0     
--------------------------------------------
158 K     Trainable params
0         Non-trainable params
158 K     Total params
0.636     Total estimated model params size (MB)
[2024-05-13T07:15:50.587+0000] {logging_mixin.py:151} INFO - Sanity Checking: |          | 0/? [00:00<?, ?it/s]
[2024-05-13T07:15:50.588+0000] {exceptions.py:175} WARNING - /home/***/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.

[2024-05-13T07:15:50.666+0000] {logging_mixin.py:151} INFO - Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]
[2024-05-13T07:15:50.666+0000] {logging_mixin.py:151} INFO - Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
[2024-05-13T07:15:50.700+0000] {logging_mixin.py:151} INFO - Sanity Checking DataLoader 0:  50%|#####     | 1/2 [00:00<00:00, 29.36it/s]
[2024-05-13T07:15:50.799+0000] {logging_mixin.py:151} INFO - Sanity Checking DataLoader 0: 100%|##########| 2/2 [00:00<00:00, 15.06it/s]
[2024-05-13T07:15:50.815+0000] {logging_mixin.py:151} INFO - k         1        10        20         5
map     0.0  0.000911  0.001330  0.000477
ndcg    0.0  0.001905  0.003486  0.000867
recall  0.0  0.005302  0.011665  0.002121
[2024-05-13T07:15:50.815+0000] {logging_mixin.py:151} INFO -                                                                            
[2024-05-13T07:15:50.817+0000] {exceptions.py:175} WARNING - /home/***/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.

[2024-05-13T07:15:50.818+0000] {exceptions.py:175} WARNING - /home/***/.local/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-13T07:15:50.818+0000] {logging_mixin.py:151} INFO - 
[2024-05-13T07:15:50.818+0000] {logging_mixin.py:151} INFO - Training: |          | 0/? [00:00<?, ?it/s]
[2024-05-13T07:15:50.818+0000] {logging_mixin.py:151} INFO - Training:   0%|          | 0/2 [00:00<?, ?it/s]
[2024-05-13T07:15:50.819+0000] {logging_mixin.py:151} INFO - Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] 
[2024-05-13T07:15:50.935+0000] {logging_mixin.py:151} INFO - Epoch 0:  50%|#####     | 1/2 [00:00<00:00,  8.59it/s]
[2024-05-13T07:15:50.936+0000] {logging_mixin.py:151} INFO - Epoch 0:  50%|#####     | 1/2 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=7.460]
[2024-05-13T07:15:51.020+0000] {logging_mixin.py:151} INFO - Epoch 0: 100%|##########| 2/2 [00:00<00:00,  9.92it/s, v_num=0, train_loss_step=7.460]
[2024-05-13T07:15:51.021+0000] {logging_mixin.py:151} INFO - Epoch 0: 100%|##########| 2/2 [00:00<00:00,  9.88it/s, v_num=0, train_loss_step=7.460]
[2024-05-13T07:15:51.023+0000] {logging_mixin.py:151} INFO - Validation: |          | 0/? [00:00<?, ?it/s]
[2024-05-13T07:15:51.023+0000] {logging_mixin.py:151} INFO - 
[2024-05-13T07:15:51.095+0000] {logging_mixin.py:151} INFO - Validation:   0%|          | 0/2 [00:00<?, ?it/s]
[2024-05-13T07:15:51.095+0000] {logging_mixin.py:151} INFO - 
[2024-05-13T07:15:51.095+0000] {logging_mixin.py:151} INFO - Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
[2024-05-13T07:15:51.095+0000] {logging_mixin.py:151} INFO - 
[2024-05-13T07:15:51.108+0000] {logging_mixin.py:151} INFO - Validation DataLoader 0:  50%|#####     | 1/2 [00:00<00:00, 75.21it/s]
[2024-05-13T07:15:51.108+0000] {logging_mixin.py:151} INFO - 
[2024-05-13T07:15:51.180+0000] {logging_mixin.py:151} INFO - Validation DataLoader 0: 100%|##########| 2/2 [00:00<00:00, 23.36it/s]
[2024-05-13T07:15:51.180+0000] {logging_mixin.py:151} INFO - 
[2024-05-13T07:15:51.189+0000] {logging_mixin.py:151} INFO - k         1        10        20         5
map     0.0  0.002180  0.002769  0.001326
ndcg    0.0  0.003858  0.006003  0.001795
recall  0.0  0.009544  0.018028  0.003181
[2024-05-13T07:15:51.195+0000] {logging_mixin.py:151} INFO -                                                                       
[2024-05-13T07:15:51.196+0000] {logging_mixin.py:151} INFO - 
[2024-05-13T07:15:51.196+0000] {logging_mixin.py:151} INFO - Epoch 0: 100%|##########| 2/2 [00:00<00:00,  5.30it/s, v_num=0, train_loss_step=7.460]
[2024-05-13T07:15:51.197+0000] {logging_mixin.py:151} INFO - Epoch 0: 100%|##########| 2/2 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=7.460, train_loss_epoch=7.460]
[2024-05-13T07:15:51.198+0000] {log.py:232} WARNING - INFO: Epoch 0, global step 2: 'recall@10' reached 0.00954 (best 0.00954), saving model to '/opt/***/model_checkpoints/epoch=0-step=2.ckpt' as top 1
[2024-05-13T07:15:51.198+0000] {rank_zero.py:63} INFO - Epoch 0, global step 2: 'recall@10' reached 0.00954 (best 0.00954), saving model to '/opt/***/model_checkpoints/epoch=0-step=2.ckpt' as top 1
[2024-05-13T07:15:51.212+0000] {log.py:232} WARNING - INFO: `Trainer.fit` stopped: `max_epochs=1` reached.
[2024-05-13T07:15:51.212+0000] {rank_zero.py:63} INFO - `Trainer.fit` stopped: `max_epochs=1` reached.
[2024-05-13T07:15:51.213+0000] {logging_mixin.py:151} INFO - Epoch 0: 100%|##########| 2/2 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=7.460, train_loss_epoch=7.460]
[2024-05-13T07:15:51.225+0000] {python.py:194} INFO - Done. Returned value was: <lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f0cd60016c0>
[2024-05-13T07:15:51.275+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=Sasrec_model_DAG, task_id=model_fit, execution_date=20240513T071532, start_date=20240513T071550, end_date=20240513T071551
[2024-05-13T07:15:51.315+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-05-13T07:15:51.332+0000] {taskinstance.py:2776} INFO - 1 downstream tasks scheduled from follow-on schedule check
