[2024-05-13T07:15:55.312+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Sasrec_model_DAG.upload_model_to_mlflow manual__2024-05-13T07:15:32.708775+00:00 [queued]>
[2024-05-13T07:15:55.319+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Sasrec_model_DAG.upload_model_to_mlflow manual__2024-05-13T07:15:32.708775+00:00 [queued]>
[2024-05-13T07:15:55.319+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2024-05-13T07:15:55.328+0000] {taskinstance.py:1380} INFO - Executing <Task(_PythonDecoratedOperator): upload_model_to_mlflow> on 2024-05-13 07:15:32.708775+00:00
[2024-05-13T07:15:55.338+0000] {standard_task_runner.py:57} INFO - Started process 561 to run task
[2024-05-13T07:15:55.341+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'Sasrec_model_DAG', 'upload_model_to_mlflow', 'manual__2024-05-13T07:15:32.708775+00:00', '--job-id', '6', '--raw', '--subdir', 'DAGS_FOLDER/sasrec_dag.py', '--cfg-path', '/tmp/tmpvs3z8tpv']
[2024-05-13T07:15:55.344+0000] {standard_task_runner.py:85} INFO - Job 6: Subtask upload_model_to_mlflow
[2024-05-13T07:15:55.377+0000] {task_command.py:415} INFO - Running <TaskInstance: Sasrec_model_DAG.upload_model_to_mlflow manual__2024-05-13T07:15:32.708775+00:00 [running]> on host a7d11f6dcbcd
[2024-05-13T07:15:55.429+0000] {instantiator.py:21} INFO - Created a temporary directory at /tmp/tmp7mon8au2
[2024-05-13T07:15:55.429+0000] {instantiator.py:76} INFO - Writing /tmp/tmp7mon8au2/_remote_module_non_scriptable.py
[2024-05-13T07:15:55.478+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='Sasrec_model_DAG' AIRFLOW_CTX_TASK_ID='upload_model_to_mlflow' AIRFLOW_CTX_EXECUTION_DATE='2024-05-13T07:15:32.708775+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-05-13T07:15:32.708775+00:00'
[2024-05-13T07:15:55.479+0000] {sasrec_dag.py:310} INFO - /opt/***
[2024-05-13T07:15:55.479+0000] {sasrec_dag.py:311} INFO - ['dags', 'logs', 'models', 'webserver_config.py', 'plugins', 'config', 'volumes', '***-worker.pid', '***.cfg', 'model_logs', 'model_checkpoints', 'requirements.txt']
[2024-05-13T07:15:55.898+0000] {sasrec_dag.py:320} INFO - SasRec(
  (_model): SasRecModel(
    (item_embedder): SasRecEmbeddings(
      (item_emb): Embedding(1683, 64, padding_idx=1682)
      (pos_emb): SasRecPositionalEmbedding(
        (pe): Embedding(10, 64)
      )
      (item_emb_dropout): Dropout(p=0.5, inplace=False)
    )
    (sasrec_layers): SasRecLayers(
      (attention_layers): ModuleList(
        (0): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (1): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
      )
      (attention_layernorms): ModuleList(
        (0): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
        (1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      )
      (forward_layers): ModuleList(
        (0): SasRecPointWiseFeedForward(
          (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
          (dropout1): Dropout(p=0.5, inplace=False)
          (relu): ReLU()
          (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
          (dropout2): Dropout(p=0.5, inplace=False)
        )
        (1): SasRecPointWiseFeedForward(
          (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
          (dropout1): Dropout(p=0.5, inplace=False)
          (relu): ReLU()
          (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
          (dropout2): Dropout(p=0.5, inplace=False)
        )
      )
      (forward_layernorms): ModuleList(
        (0): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
        (1): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
      )
    )
    (output_normalization): SasRecNormalizer(
      (last_layernorm): LayerNorm((64,), eps=1e-08, elementwise_affine=True)
    )
    (_head): EmbeddingTyingHead(
      (_item_embedder): SasRecEmbeddings(
        (item_emb): Embedding(1683, 64, padding_idx=1682)
        (pos_emb): SasRecPositionalEmbedding(
          (pe): Embedding(10, 64)
        )
        (item_emb_dropout): Dropout(p=0.5, inplace=False)
      )
    )
  )
  (_loss): CrossEntropyLoss()
)
[2024-05-13T07:15:56.348+0000] {logging_mixin.py:151} WARNING - 2024/05/13 07:15:56 INFO mlflow.tracking.fluent: Experiment with name 'sasrec' does not exist. Creating a new experiment.
[2024-05-13T07:15:56.883+0000] {logging_mixin.py:151} WARNING - 2024/05/13 07:15:56 INFO mlflow.types.utils: Unsupported type hint: typing.List[int], skipping schema inference
[2024-05-13T07:15:56.883+0000] {logging_mixin.py:151} WARNING - 2024/05/13 07:15:56 INFO mlflow.types.utils: Unsupported type hint: typing.List[int], skipping schema inference
[2024-05-13T07:15:56.898+0000] {exceptions.py:175} WARNING - /home/***/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

[2024-05-13T07:15:57.399+0000] {logging_mixin.py:151} WARNING - Successfully registered model 'sasrec'.
[2024-05-13T07:15:57.472+0000] {logging_mixin.py:151} WARNING - 2024/05/13 07:15:57 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: sasrec, version 1
[2024-05-13T07:15:57.472+0000] {logging_mixin.py:151} WARNING - Created version '1' of model 'sasrec'.
[2024-05-13T07:15:57.493+0000] {python.py:194} INFO - Done. Returned value was: True
[2024-05-13T07:15:57.512+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=Sasrec_model_DAG, task_id=upload_model_to_mlflow, execution_date=20240513T071532, start_date=20240513T071555, end_date=20240513T071557
[2024-05-13T07:15:57.555+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-05-13T07:15:57.570+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
